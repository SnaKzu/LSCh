# ğŸ¤Ÿ Traductor de Lengua de SeÃ±as Peruana (LSP) a Texto y Voz

Sistema de reconocimiento en tiempo real de Lengua de SeÃ±as Peruana usando **LSTM + MediaPipe**. Detecta seÃ±as mediante cÃ¡mara, las traduce a texto espaÃ±ol y genera sÃ­ntesis de voz.

[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15.0-orange)](https://tensorflow.org)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://python.org)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10.11-green)](https://mediapipe.dev)

---

## ğŸ¯ CaracterÃ­sticas

- âœ… **DetecciÃ³n en tiempo real** de 14 palabras en LSP
- âœ… **Interfaz grÃ¡fica** con PyQt5
- âœ… **SÃ­ntesis de voz** automÃ¡tica (Text-to-Speech)
- âœ… **API REST** con Flask para integraciÃ³n
- âœ… **ConfiguraciÃ³n centralizada** en YAML
- âœ… **Pipeline completo**: Captura â†’ Entrenamiento â†’ Inferencia

---

## ğŸ“‹ Vocabulario (14 palabras)

```
Saludos:     hola, buenos dÃ­as, buenas tardes, buenas noches, adiÃ³s
Estados:     bien, mal, mÃ¡s o menos
CortesÃ­a:    gracias, por favor, disculpa, me ayudas
Preguntas:   cÃ³mo estÃ¡s
```

---

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: Script AutomÃ¡tico (Recomendado)

```powershell
# Clonar o descargar el proyecto
cd modelo_lstm_lsp-main

# Ejecutar script de setup
.\setup.ps1
```

### OpciÃ³n 2: Manual

```powershell
# 1. Crear entorno virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# 2. Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt

# 3. Verificar instalaciÃ³n
python -c "from config_manager import config; print('âœ“ OK')"
```

---

## ğŸ“š Uso del Sistema

### 1ï¸âƒ£ Usar Modelo Preentrenado (MÃ¡s RÃ¡pido)

```powershell
# Interfaz grÃ¡fica
python main.py

# Modo consola (sin GUI)
python evaluate_model.py
```

### 2ï¸âƒ£ Entrenar Tu Propio Modelo (Completo)

```powershell
# Paso 1: Capturar muestras (30-50 por palabra)
python capture_samples.py

# Paso 2: Normalizar frames a 15 por muestra
python normalize_samples.py

# Paso 3: Extraer keypoints (1662 valores por frame)
python create_keypoints.py

# Paso 4: Entrenar red LSTM
python training_model.py

# Paso 5: Evaluar resultados
python evaluate_model.py
```

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ENTRADA: Video (CÃ¡mara)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MediaPipe Holistic (Google)            â”‚
â”‚  Detecta: Pose (33) + Cara (468) +          â”‚
â”‚          Manos (21+21) = 1662 keypoints     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      NormalizaciÃ³n a 15 frames              â”‚
â”‚  Interpola/Submuestrea secuencias           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Red Neuronal LSTM                     â”‚
â”‚  LSTM(64) â†’ LSTM(128) â†’ Dense â†’ Softmax     â”‚
â”‚  Input: (15, 1662) â†’ Output: (14 clases)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SALIDA: Texto + Voz (gTTS)             â”‚
â”‚  Ej: "BUENOS DÃAS" + audio.mp3              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ ConfiguraciÃ³n

Toda la configuraciÃ³n estÃ¡ centralizada en **`config.yaml`**:

```yaml
# ParÃ¡metros del modelo
model:
  frames: 15              # Frames por secuencia
  keypoints_length: 1662  # DimensiÃ³n del vector
  min_length_frames: 5    # MÃ­nimo para validar seÃ±a

# HiperparÃ¡metros de entrenamiento
training:
  epochs: 500
  batch_size: 8
  validation_split: 0.05
  early_stopping_patience: 10

# Arquitectura de red
network:
  lstm1_units: 64
  lstm2_units: 128
  dropout: 0.5

# Vocabulario
vocabulary:
  word_ids: [adios, bien, buenos_dias, ...]
  word_labels:
    buenos_dias: "BUENOS DÃAS"
```

Para modificar, edita `config.yaml` y reent rena el modelo.

---

## ğŸ“ Estructura del Proyecto

```
modelo_lstm_lsp-main/
â”œâ”€â”€ config.yaml              # âš™ï¸ ConfiguraciÃ³n central
â”œâ”€â”€ config_manager.py        # ğŸ“¦ Gestor de configuraciÃ³n
â”œâ”€â”€ requirements.txt         # ğŸ“‹ Dependencias
â”œâ”€â”€ setup.ps1                # ğŸš€ Script de instalaciÃ³n
â”œâ”€â”€ MIGRATION_GUIDE.md       # ğŸ“– GuÃ­a de migraciÃ³n
â”‚
â”œâ”€â”€ model.py                 # ğŸ§  Arquitectura LSTM
â”œâ”€â”€ training_model.py        # ğŸ“ Entrenamiento
â”œâ”€â”€ evaluate_model.py        # ğŸ§ª EvaluaciÃ³n
â”œâ”€â”€ main.py                  # ğŸ–¥ï¸ Interfaz grÃ¡fica
â”‚
â”œâ”€â”€ capture_samples.py       # ğŸ“¹ Captura de datos
â”œâ”€â”€ normalize_samples.py     # âš–ï¸ NormalizaciÃ³n
â”œâ”€â”€ create_keypoints.py      # ğŸ”‘ ExtracciÃ³n keypoints
â”‚
â”œâ”€â”€ helpers.py               # ğŸ› ï¸ Utilidades
â”œâ”€â”€ constants.py             # ğŸ“Œ Constantes (legacy)
â”œâ”€â”€ text_to_speech.py        # ğŸ”Š SÃ­ntesis de voz
â”œâ”€â”€ server.py                # ğŸŒ API REST
â”‚
â”œâ”€â”€ models/                  # ğŸ’¾ Modelos entrenados
â”‚   â”œâ”€â”€ actions_15.keras
â”‚   â””â”€â”€ words.json
â”‚
â”œâ”€â”€ data/                    # ğŸ“Š Datos procesados
â”‚   â””â”€â”€ keypoints/
â”‚
â””â”€â”€ frame_actions/           # ğŸ¬ Muestras de video
    â”œâ”€â”€ hola/
    â”œâ”€â”€ buenos_dias/
    â””â”€â”€ ...
```

---

## ğŸ”§ Agregar Nueva Palabra

### 1. Editar `config.yaml`

```yaml
vocabulary:
  word_ids:
    - "adios"
    - "bien"
    - "tu_nueva_palabra"  # â† Agregar aquÃ­
  
  word_labels:
    tu_nueva_palabra: "TU NUEVA PALABRA"
```

### 2. Capturar Muestras

```python
# En capture_samples.py, lÃ­nea final:
word_name = "tu_nueva_palabra"
word_path = os.path.join(ROOT_PATH, FRAME_ACTIONS_PATH, word_name)
capture_samples(word_path)
```

Ejecutar: `python capture_samples.py` (grabar 30-50 muestras)

### 3. Procesar y Entrenar

```powershell
python normalize_samples.py
python create_keypoints.py
python training_model.py
```

---

## ğŸŒ API REST

Iniciar servidor:

```powershell
python server.py
```

Endpoint disponible:

```bash
POST http://localhost:5000/upload_video
Content-Type: multipart/form-data

{
  "video": <archivo_video>
}

# Respuesta:
"HOLA - BUENOS DÃAS - GRACIAS"
```

---

## ğŸ“Š MÃ©tricas y EvaluaciÃ³n

```python
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

# Generar matriz de confusiÃ³n
python confusion_matrix.py

# Ver historial de entrenamiento
# AutomÃ¡tico en training_model.py
```

---

## ğŸ› SoluciÃ³n de Problemas

### Error: `ModuleNotFoundError: No module named 'yaml'`
```powershell
pip install PyYAML
```

### Error: `cannot import name 'builder' from 'google.protobuf'`
```powershell
pip install protobuf==3.20.3 --force-reinstall
```

### Error: MediaPipe no funciona en Python 3.12
```powershell
# Usar Python 3.10 o 3.11
python3.10 -m venv venv
```

### Error al cargar modelo `.keras`
```powershell
# Reentrenar con TensorFlow actual
python training_model.py
```

MÃ¡s soluciones en **`MIGRATION_GUIDE.md`**

---

## ğŸ“– DocumentaciÃ³n

- **`MIGRATION_GUIDE.md`** - GuÃ­a de migraciÃ³n a TensorFlow 2.15+
- **`config.yaml`** - ConfiguraciÃ³n con comentarios
- **CÃ³digo fuente** - Docstrings completos en cada funciÃ³n

---

## ğŸ“ TecnologÃ­as Utilizadas

| TecnologÃ­a | PropÃ³sito |
|------------|-----------|
| **TensorFlow/Keras** | Red neuronal LSTM |
| **MediaPipe** | DetecciÃ³n de pose y manos |
| **OpenCV** | Procesamiento de video |
| **PyQt5** | Interfaz grÃ¡fica |
| **Flask** | API REST |
| **gTTS + pygame** | SÃ­ntesis de voz |
| **NumPy/Pandas** | Manejo de datos |
| **PyYAML** | ConfiguraciÃ³n |

---

## ğŸ“ Requisitos del Sistema

- **Python:** 3.10, 3.11 o 3.12
- **RAM:** MÃ­nimo 4GB (8GB recomendado)
- **GPU:** Opcional (acelera entrenamiento)
- **CÃ¡mara:** Para captura y evaluaciÃ³n en tiempo real
- **Espacio:** ~2GB (dependencias + datos)

---

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama: `git checkout -b feature/nueva-palabra`
3. Commit cambios: `git commit -m 'Agrega palabra X'`
4. Push: `git push origin feature/nueva-palabra`
5. Abre un Pull Request

---

## ğŸ“¹ Video Tutorial

[Video explicativo del cÃ³digo](https://youtu.be/3EK0TxfoAMk)

---

## ğŸ“œ Licencia

Este proyecto es de cÃ³digo abierto para fines educativos y de investigaciÃ³n.

---

## ğŸ‘¨â€ğŸ’» Autor

Proyecto de reconocimiento de Lengua de SeÃ±as Peruana usando Deep Learning

---

## ğŸ†• Changelog

### v2.0 (Octubre 2025)
- âœ… Actualizado a TensorFlow 2.15.0
- âœ… ConfiguraciÃ³n centralizada con YAML
- âœ… Mejor arquitectura de cÃ³digo
- âœ… Script de instalaciÃ³n automÃ¡tica
- âœ… DocumentaciÃ³n mejorada

### v1.0 (Inicial)
- âœ… ImplementaciÃ³n bÃ¡sica con TensorFlow 2.10
- âœ… 14 palabras en LSP
- âœ… Interfaz grÃ¡fica PyQt5

---

**Â¡Felicidades! Ahora tienes un sistema completo de reconocimiento de LSP. ğŸ‰**

Para comenzar, ejecuta: `.\setup.ps1`
